<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cyc | IFHO]]></title>
  <link href="http://gurgeh.github.com/blog/categories/cyc/atom.xml" rel="self"/>
  <link href="http://gurgeh.github.com/"/>
  <updated>2012-09-28T17:09:16+02:00</updated>
  <id>http://gurgeh.github.com/</id>
  <author>
    <name><![CDATA[David Fendrich]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Coincidence?]]></title>
    <link href="http://gurgeh.github.com/blog/2007/09/06/coincidence/"/>
    <updated>2007-09-06T00:00:00+02:00</updated>
    <id>http://gurgeh.github.com/blog/2007/09/06/coincidence</id>
    <content type="html"><![CDATA[<div class='post'>
I once read a short story about the creation of the world's most powerful computer. In essence, each time they tried to turn it on, they had some minor misfortune, a power outage, the maid accidentaly tripped on, and unplugged, the power cord, etc. The highly technical twist in the end was that since we live in a <a href="http://en.wikipedia.org/wiki/Multiverse">Multiverse</a>, all things that can happen happens in a separate universe. It turns out that the computer was so advanced (or something) that it turned in to a black hole when switched on, destroying all life. Since the observers could only exist in the universes where the computer remained switched off, they experienced these "coincidences", that protected them.<br /><br /><span style="font-size:130%;">A database of all human knowledge</span><br /><br />When I read up a bit on <a href="http://en.wikipedia.org/wiki/Cyc">Cyc</a>, the other day, I came upon a competing project that I, myself, once added some <span style="font-style: italic;">mindpixels</span> to.<a href="http://en.wikipedia.org/wiki/Mindpixel"> </a><blockquote><a href="http://en.wikipedia.org/wiki/Mindpixel">Mindpixel</a> was a web-based collaborative <a href="http://en.wikipedia.org/wiki/List_of_notable_artificial_intelligence_projects" title="List of notable artificial intelligence projects"></a>artificial intelligence project which aimed to create a database of millions of human validated true/false statements, or probabilistic propositions.</blockquote>Unfortunately the project is now defunct, since the founder Chris McKinstry committed suicide on <a href="http://en.wikipedia.org/wiki/23rd_January" title="23rd January"></a>23rd January, 2006.<a href="http://en.wikipedia.org/wiki/2006" title="2006"></a><br /><br />Well, never fear, because from the Mindpixel page on Wikipedia, we learn that <a href="http://en.wikipedia.org/wiki/Open_Mind_Common_Sense">Open Mind Common Sense</a> is a similar project, run by MIT, whose goal is to build a large common sense knowledge base from the contributions of many thousands of people across the Web.<br /><br />Unfortunately that<span style="font-weight: bold;"> </span>project is <span style="font-weight: bold;">also</span> stalling, since Push Singh who was slated to become a professor at the MIT Media Lab to lead the Commonsense Computing group in 2007, commited suicide on Tuesday, February 28, 2006. Just a month after the other visionary of web knowledge, Chris McKinstry.<br /><br />Let the unreasonable conspiracy theories commence.<br /><a href="http://en.wikipedia.org/wiki/Deaths_in_February_2006" title="Deaths in February 2006"></a></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Seed AI]]></title>
    <link href="http://gurgeh.github.com/blog/2007/08/30/seed-ai/"/>
    <updated>2007-08-30T00:00:00+02:00</updated>
    <id>http://gurgeh.github.com/blog/2007/08/30/seed-ai</id>
    <content type="html"><![CDATA[<div class='post'>
<span style="font-size:130%;">Le grand assumption<br /><br /></span>The assumption of <a href="http://en.wikipedia.org/wiki/Seed_AI">seed AI</a> is this: <blockquote>If we can make a program intelligent enough, a "seed" of intelligence, we can also make it gradually improve itself.</blockquote>If intelligence can be expressed as a short formula (think Maxwell's equations or E = mc<sup>2</sup>), we might not need to make a seed. We will simply have to find that formula. In general, the <a href="http://en.wikipedia.org/wiki/No-free-lunch_theorem">No-Free-Lunch theorem</a> implies that there must always be scope for improvement, but there are nevertheless some promising paths that I will post about some other time.<br /><br />Related to seed AI is the point where an AI can read and make sense of human text, such as Wikipedia, Principia Mathematica, etc. If we can reach that goal, an AI would quickly acquire superhuman cross-disciplinary knowledge, which in turn would help it to digest ever more advanced text. To get there, a program has to have plenty of common sense that we all take for granted. <a href="http://en.wikipedia.org/wiki/Cyc">Cyc</a> is an ambitious, long-running, project that tries to collect all this "common sense".<br /><br />A superintelligent AI would be incredibly useful. Useful beyond your wildest fantasies. <sing>.<br /><br />A more intelligent program is likely harder to improve, but at the same time a more intelligent program is better at improving, so we can have reasonable hope for the improvement process to continue indefinitely (or perhaps converge to a single point - the formula for intelligence), although it is hard to guess what the improvement curve will look like. Will the difficulty increase much faster than the capacity? No one knows. It is tempting to make an analogy with humans and note how hard it is for us to rewire the brain to make us fundamentally more intelligent. For most programs this is probably very different. A program is made to be modified, it is software and not, as our brains, firmware or wetware.<br /><br />If we want to talk about improving programs, <span style="font-weight: bold;">we have to define what it means to improve one's intelligence, and thus what it means to be intelligent</span>. We want intelligent systems to be useful. Useful intelligence is, just as science, about <span style="font-style: italic;">prediction, planning and pattern recognition</span>. These are all so intertwined as to be more or less the same thing.<br /><br /><span style="font-size:130%;">Prediction<br /><br /></span>Given certain input we want to predict what the outcome might be. It is nice if this prediction involves not only the most likely outcome, but also estimates of the probabilities of all the possible outcomes. Even better is if the predictor gives an indication for how certain it is about the probabilities.<br /><br />If I roll a regular dice, I am fairly sure that the probability of a 3 showing up is about 16.7%, of course the dice might be damaged or otherwise unfair, or perhaps I miscalculated 1 / 6 or misunderstand the laws of probability, etc. Neverthless, I am fairly certain. On the other hand, I estimate the probability of Sweden beating Brazil the next time they meet in soccer to about 10%, but I am fairly uncertain about that figure. Thus I should be cautious about acting on it, for example not taking bets. I am, however, quite certain that I am uncertain about my last probability estimation. It is probably not very useful to continue this recursion further, neither for me nor for a program, so I'll be quite satisfied if my AI knows certainties concerning probabilities, but not certainties about certainties.<br /><br />Two classic examples where prediction is useful are weather forecasts and the stock market.<br /><br /><br /><span style="font-size:130%;">Planning</span><br /><br />Prediction is closely related to planning. One way of formalizing planning is to make an enormous tree, where each choice I can make is a branching point and every consequence along with it's probability is also a branching point. In a complex world most of my millions of choices/actions will not have any bearing on me reaching a specific goal, so the tree gets unfeasibly large. The first step is to quickly <span style="font-weight: bold;font-size:100%;" >predict</span><span style="font-size:100%;"> which paths might actually have a significance towards me reaching my goal, thus pruning the tree. Then I have to </span><span style="font-weight: bold;font-size:100%;" >predict</span><span style="font-size:100%;"> what the consequences of my actions are likely to be, making a model of the outside world. Now I have a tree where I can start searching for a solution, in other words make a plan<br /><br />A classic example of a planning problem is <a href="http://en.wikipedia.org/wiki/Towers_of_Hanoi">Towers of Hanoi</a>. It is trivially easy to make a program that solves Towers of Hanoi, but it is harder to construct a general AI that, given the rules to the game, solves it in general. You cannot just exhaustively search your decision tree, because Towers of Hanoi with 30 discs requires 2^30 - 1= 1073741823 moves to complete. This means that the depth of the tree is 10^9 and, given at least two paths on each level, 2^(10^9) nodes. That amounts to more than a 1 followed by 300 million zeroes - a ridiculously large number. The planner must reason about the effects of the rules and <span style="font-style: italic;">recognize the pattern</span> for moving the discs.<br /><br /><br /><span style="font-size:130%;">Pattern recognition<br /></span><br />Recognizing patterns is, among other things, the useful property of being able to spot that given <span style="font-style: italic;">this</span>, <span style="font-style: italic;">that</span> follows more/less frequently. A neat way of deciding if you have spotted a pattern is to invoke <a href="http://en.wikipedia.org/wiki/Minimum_description_length">Minimum Description Length</a> or MDL. 10101010101010... can be described with the exact digits, or as a repeating pattern of 10s or as alternating 1 and 0. Which one is chosen depends on what language you have chosen to express your pattern in. For longer patterns it makes less and less difference what language you chose. The same reasoning applies to, for example, a picture. If we have a completely black 1000 x 1000 pixel square with a white 500 pixel (in diameter) circle in the middle , then that description is much shorter than actually encoding the image pixel for pixel. We have recognized a pattern.<br /><br />Notice the close relationship between pattern recognition and compression.<br /><br /><span style="font-size:130%;">Intelligence test<br /></span><br />Constructing a true intelligence test, that can be executed reasonably fast, would be very useful in the research of general AI. You have to be careful when designing such a test, because if it is too simple you will end up with an AI that is specialized on solving exactly your test and nothing else.<br /><br />If we had such a test, a fairly simple, but very interesting, experiment could be made.<br /></span></sing><ol><li><span style="font-size:100%;">Start with a program that produces random output. The seed!</span></li><li><span style="font-size:100%;">Measure its intelligence. This producer of random noise is now your first and most intelligent program.</span></li><li><span style="font-size:100%;">Interpret the currently best program's output as new programs and measure the intelligence of these programs, give this intelligence as feedback to the generating program.</span></li><li><span style="font-size:100%;">Whenever a program that is more intelligent than the previous most intelligent program is found, use it as the new generator to search for even more intelligent programs.</span></li></ol><span style="font-size:100%;">You might need to add some precautions so that you do not enter an evolutionary dead end, for example by letting different promising generators run in parallell, but the above points are the basic gist of it. This will let you find out how much more time it takes for each successively more intelligent program to construct an even more intelligent program. If you are very, very, lucky and have constructed your intelligence test very well, this might even suffice as the Seed.<br /><br />In coming posts I will describe what the mathematically perfect predictor looks like and what the mathematically perfect planner looks like. They are, at least on the surface, surprisingly dissimilar.<br /></span></div>


<h2>Comments</h2>


<div class='comments'>
<div class='comment'>
<div class='author'>cognomad</div>
<div class='content'>
Thanks for the comment on my knol, David!<BR/>You&#39;re right, it sounds very similar on a high level, &amp; I am sure there are many people who&#39;d agree with the definition. But I don&#39;t know of anyone who used it to derive a universal, low-level, quantitative criterion to select inputs &amp; algorithms. The key is to start from the beginning: raw sensory inputs, &amp; &quot;test&quot; their predictive value, in the process discovering more &amp; more complex patterns. That&#39;s what scalability is all about, if you can&#39;t evaluate pixels, it&#39;ll be super-exponentially more difficult to start from more complex data. That&#39;s why I think Cyc, NLP, &amp; high-level approaches in general are hopeless for AGI.<BR/>I am sorry, but your &quot;Intelligence test&quot; idea, besides it being entirely hypothetical &amp; presumably externally administered, has it exactly backwards. Just like many Algorithmic Learning approaches, you want to generate patterns &amp; algorithms, instead of discovering them in a real world. Quite simply, we predict from experience, these patterns &amp; algorithms will have *no* predictive value beyond mere chance, unless they&#39;re derived from the experience. Notice that the difference between patterns &amp; algorithms is strictly in their origin: the former are discovered &amp; the later are &quot;invented&quot;.</div>
</div>
</div>

]]></content>
  </entry>
  
</feed>
