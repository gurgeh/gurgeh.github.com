
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>IFHO</title>
  <meta name="author" content="David Fendrich">

  
  <meta name="description" content="Nowadays with constexpr, we can make pure functions that are
calculated compile time. The restriction on these functions is that
they may only &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://fendrich.se/">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="IFHO" type="application/atom+xml">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  
<!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">


  

</head>


<body   >
  <header role="banner"><hgroup>
  <div id="logo">
  <!--  <div id="logoLeft">{</div><div id="logText"><img src="/images/SimpsonDavid.png" width="36" height="36"></div><div id="logoRight">}</div>
  	<div class="clear"></div>-->
  </div>
  <h1><a href="/">IFHO</a></h1>
  
    <h2>In Fendrich's Humble Opinion</h2>
  
  <div class="clear"></div>
</hgroup>


</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:fendrich.se" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2012/11/22/compile-time-loops-in-c-plus-plus-11-with-trampolines-and-exponential-recursion/">Compile Time Loops in C++11 With Trampolines and Exponential Recursion</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2012-11-22T15:05:00+01:00" pubdate data-updated="true">Nov 22<span>nd</span>, 2012</time>
        
         | <a href="/blog/2012/11/22/compile-time-loops-in-c-plus-plus-11-with-trampolines-and-exponential-recursion/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Nowadays with <em>constexpr</em>, we can make pure functions that are
calculated compile time. The restriction on these functions is that
they may only consist of one statement (though additional lines with
typedefs, static_assert, etc are OK), and this statement may only call
other constexpr functions.</p>

<p>If-statements are easy - just use the ternary ?: operator or, if you
want to show off, template specialization. But the only way to loop
with these restrictions is by using recursion. Furthermore, neither
clang 3.1 nor GCC 4.7 (nor the current build of GCC 4.8) support tail
call elimination in these constexprs, so normal linear loops will
still eat stack space if we loop for a while. Also, the standard
recommends that the default maximum recursion depth should be 512,
which means that if we want to do something silly/fun/interesting
compile time, we have to mess with proprietary compiler switches to
get the program to compile. No fun.</p>

<p>In this post, I show one way of working around those limitations.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2012/11/22/compile-time-loops-in-c-plus-plus-11-with-trampolines-and-exponential-recursion/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2012/10/31/c-plus-plus-11-and-boost-succinct-like-python/">C++11 and Boost - Succinct Like Python</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2012-10-31T13:05:00+01:00" pubdate data-updated="true">Oct 31<span>st</span>, 2012</time>
        
         | <a href="/blog/2012/10/31/c-plus-plus-11-and-boost-succinct-like-python/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>C++11 is the new standard of C++ that was released last year. Yes, I know that is now 2012, but compilers are just now starting to catch up and implement everything, though AFAIK there is not yet a fully compliant compiler.</p>

<p>With a combination of C++11 and the <a href="http://www.boost.org/">Boost</a> library, I think that it is possible to write code in a style that is almost as painless as in a modern dynamic language like Python. I also think that is not so well known how much C++ has changed for the better, outside the C++-community. Hence this post.</p>

<p>As an example, I have taken the first interesting excercise from <a href="http://www.diveintopython.net/toc/index.html">Dive into Python</a>, <a href="http://www.diveintopython.net/object_oriented_framework/index.html">fileinfo.py</a>, and converted it to C++, trying to remain as faithful as possible to the original code.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2012/10/31/c-plus-plus-11-and-boost-succinct-like-python/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2012/09/28/no/">No, Really. Use Zsh.</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2012-09-28T13:23:00+02:00" pubdate data-updated="true">Sep 28<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/09/28/no/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://zsh.sourceforge.net/">Zsh</a> is the new hotness. Well newer and hotter than Bash anyway, since the first version of Bash was released in June 1989, while the young and peppy Zsh was released in December 1990. In large parts thanks to the configuration &#8220;skin&#8221; <a href="https://github.com/robbyrussell/oh-my-zsh">oh-my-zsh</a>, Zsh has gained a lot of popularity during the last year or so. I have used it for a few months myself and could not be happier, unless it produced chocolate ice cream ‚Üê <em>note to shell developers</em>.</p>

<p>This is a guide on why you need it and how you install, configure and use it. Sometimes just with links to the relevant sites.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2012/09/28/no/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2012/09/27/octopress-and-github-as-blogging-platform/">Octopress and Github as a Blogging Platform</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2012-09-27T16:37:00+02:00" pubdate data-updated="true">Sep 27<span>th</span>, 2012</time>
        
         | <a href="/blog/2012/09/27/octopress-and-github-as-blogging-platform/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I have switched from Blogspot to <a href="http://octopress.org">Octopress</a>. Any self respecting coder should realize that 1) blogging is text and 2) text should be in revision control. Also 3) blogging is public text, so the revision control can be on a public server, like Github.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2012/09/27/octopress-and-github-as-blogging-platform/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2011/11/10/guerilla-my-attempt-to-build-strong-ai/">Guerilla - My Attempt to Build a Strong AI</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2011-11-10T00:00:00+01:00" pubdate data-updated="true">Nov 10<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Having given the topic of artificial general intelligence (or AGI) a fair amount of thought over the last decade, a plausible path forward, based on something like an encyclopedia for algorithms, has slowly congealed in my head. I need to write it down before I start coding. Preferably in the form of a blog post, to get feedback. This is that post.<br /><br /><span class="Apple-style-span" style="font-size: large;">Background</span><br /><br />When I write about strong AI or AGI, I mean an algorithm with general problem solving skills. Not necessarily a mind inhabiting a robot, running around talking to people and passing the Turing test (though eventually a successful AGI could be taken in that direction), but rather something that can be applied to a wide variety of problems. For example: playing chess and poker, picking stocks, solving puzzles, proving math theorems, analyzing and writing computer code, speech and image recognition, improve itself by learning and self modification, etc.<br /><br /><br />There is an alluring approach to AGI, where you begin with a &#8220;simple&#8221; seed program, which will learn and self improve and eventually evolve to human intelligence and beyond. I think that in practice, the problem is that it has taken lots of people lots of time to invent all those algorithms that can be useful in general problem solving.&nbsp;Humans are pretty good at general problem solving - certainly much better than the best software/hardware combination we have today. Constructing algorithms to solve specific problems is in itself a kind of problem solving, and we humans have certainly invented many different algorithms for a wide variety of purposes. One might suspect that&nbsp;the computational depth of inventing/discovering algorithms is very large.&nbsp;So unless the seed program is actually very advanced, more like a full grown Sequoia than a seed, it might take too much time for it to invent all those algorithms and heuristics that we, as a civilization, already have.<br /><br /><br />Topics that are potentially useful to understand include:<br /><br /><br /><ul><li>Statistics (Bayes rule, distributions, Markov chains, running an experiment, etc).</li><li>Algorithms for optimizing parameters (genetic algorithms, simulated annealing, steepest descent, linear programming, random testing and purely analytical methods). In some situations it could take days or more to try a single parameter configuration. In other situations evaluating the fitness of a parameter configuration is just a couple of CPU instructions. Approaching these different tasks require a variety of methods</li><li>Logic</li><li>Basic mathematics (calculus, algebra, geometry, etc)</li><li>Code analysis (lambda calculus, etc)</li><li>Formal proof methods (knowledge of the methods listed here: http://en.wikipedia.org/wiki/Mathematical_proof) and formal reasoning</li><li>Tree and graph searching (depth-first, breadth-first, A*, beam, minimax, alpha-beta, Dijkstra)</li><li>Bayesian belief networks</li><li>Pattern recognition</li><li>Compression</li><li>Monte Carlo method</li><li>Clustering and classification</li><li>Fourier transforms, wavelets</li><li>Function approximation (analytical or with neural networks or genetic programming)</li><li>Inverting functions (in other words, given a program function and its output tell me what the input was - this turn out to be a very general way of posing questions)</li></ul><br /><div>&#8230;and of course many more.</div><div><br /></div><div>I consider statistics and parameter optimization to be the most important areas for intelligence, since you need them to learn. Pattern recognition (perhaps implemented with statistics and optimization) and various forms of tree searching are also vital.</div><br /><span class="Apple-style-span" style="font-size: large;">An encyclopedia of algorithms</span><br /><br />My approach is based on implementing an encyclopedia of useful algorithms that:<br /><br /><ol><li>Know to which tasks they can be applied</li><li>Can give a rough, initially often ridiculously rough, estimate of what the probability is that they solve the task after a certain time or, in the case of an open-ended task such as optimization, can give a rough estimate of how well the task is solved after a certain time.</li><li>Can continuously update the estimate as the task is solved</li></ol><br />It is important to stress that it is not enough to just implement a library of algorithms that can work on the same datastructures. The important thing is that you need metadata, describing when an algorithm can be used and the algorithmic complexity in time and memory. With time, you want to automatically build up more knowledge of the algorithms, gradually improving the time and success estimations as well as improving your knowledge of which algorithms are suitable in which situations.<br /><br />The algorithms should be broken up into as many natural subtasks as possible, so that when new algorithms are added to the system, they can try to solve these subtasks as well, thus creating new hybrid algorithms.<br /><br />A <i>task</i> is basically a function call together with its arguments. An algorithm that can solve a task implements the corresponding function and a time/success estimator. Similarly to function overloading in C++, the function header might state specializations, additional properties, of the function arguments that must be true for the algorithm to be a contender to solve it. It is important that the <i>Scheduler</i> (see below) immediately knows which algorithms are suitable for a certain task, so the mentioned &#8220;additional argument properties&#8221; must be immediately available. If a certain property requires work to find out - &#8220;is the list in the first argument sorted?&#8221; - and an algorithm still needs it, a new algorithm can be constructed that first checks if the list is sorted and then either fails or asks the task again with the new property set. This new algorithm would have higher estimates of running time and lower estimates of success than the original algorithm.<br /><br /><span class="Apple-style-span" style="font-size: large;">The Scheduler</span><br /><br />When a task is added to the task pool it always has a <i>price</i> attached to it. The Scheduler runs those algorithms that currently promise best expected price per time unit. Algorithms that need subtasks solved has to assign a price to those too, before adding them to the task pool. That price should reasonably reflect how much of the overall time the subtask is expected to take. If it turns out that a subtask consistently take a smaller or larger fraction of the estimated total time, there should be algorithms that modify the price for these subtasks and correspondingly the total time estimate (also, see <i>Self Improvement</i> below).<br /><br />Open-ended tasks where something should be optimized cannot have just one value attached to them. Instead they need to have a function from achieved performance to price, or at least a rough mapping from some performance values to price. This mapping stops the system from optimizing for too long on a relatively unimportant subsubsubtask somewhere.<br /><br />Algorithms that can either fail or succeed on a task need a similar mapping, where they give probability of success as a function of time.<br /><br />One can also imagine that the algorithms could give a confidence interval or standard deviation on their estimates to tell the Scheduler how sure they are of their estimates, but I am not quite sure how this should be used, so for now they won&#8217;t.<br /><br />For my first try, the Scheduler will use a simple heuristic. The algorithm that claims to have the best price / time ratio for any task currently in the task pool will get to run it. For one thread this will be optimal in some sense. It gets more complex when you have many algorithms running in parallel on multiple cores or even clusters. For example, you want to slightly punish two algorithms trying to complete the same task in parallel, since the first one to succeed will always make the other algorithms work moot. On the other hand sometimes it makes sense to attack an important problem from several angles, so you don&#8217;t want to forbid it entirely either.<br /><br />In a later design, the Scheduler should be able to use the task pool to think about how it should Schedule. Obviously this must not end in an infinite Scheduling loop or general inefficiency, since normally the Scheduler must work very quickly.<br /><br />The Scheduler&#8217;s work and indeed that of the whole system will not be especially interesting when there are only a few algorithms implemented. The first interesting moment will be when new hybrid algorithms emerge, where subtasks are sometimes handled by unanticipated algorithms. I am not sure how many algorithms needs to be implemented for the system to show interesting emergent behaviour. Probably more than ten, but less than a hundred, depending, of course, on which algorithms and what you count as an individual algorithm.<br /><br /><span class="Apple-style-span" style="font-size: large;">Self improvement</span><br /><br />From the above, you can see that the system will not be self improving at first. However, by adding self improvement tasks, it will start doing things like improving the time estimates of the algorithms, learn to what degree one algorithm&#8217;s failure to solve a task should also reflect on the estimates of other algorithms, learn which situations are suitable for which algorithms; for example which algorithms perform well on the subtasks posted from a certain algorithm. It can also have an algorithm that constructs new lower-priced training tasks from real tasks, for example generalizations or specializations of a problem, just out of &#8220;curiosity&#8221;.<br /><br />Producing new/improved code and algorithms, either for self improvement or as the solution for a puzzle or some other task, is among the most advanced tasks the system can try. It will not be able to do much of interest in this area until it is really strong, but it could start out by trying simple modifications of existing algorithms or trying them on similar tasks, a bit like in genetic programming.<br /><br />The system is also inherently self improving from a sort of network effect, since for each algorithm added, the existing algorithms get potentially better.<br /><br /><span class="Apple-style-span" style="font-size: large;">What now?</span><br /><br />When I have implemented the base system, I will start by applying the AGI to function inversion. Trivial stuff at first, of course, but I hope to eventually make it solve real puzzles like Towers of Hanoi by a combination of searching and deduction. Also, it would be fun to try some games and an NP-complete problem like 3-SAT.<br /><i><br /></i><br />It would be beautiful if the algorithms were written in the same simplified, purely functional (thus easier to analyze), LISP that I plan to write the problem definitions in. Alas, good AI needs to be fast and a 100x slower system just because the algorithms run in my own immature poorly interpreted language instead of C is not so fun. However, a good JIT compiler is a very good test for an AGI. You continuously have to weigh optimization time against running what you have. If the AGI in some distant future JITs its own code, effectively running and optimizing itself, I will consider the entire project a grand success :).<br /><br />I forget why I called the project Guerilla. It was probably terribly clever. Nevertheless, here is the link to the Github repository:&nbsp;<a href="https://github.com/gurgeh/Guerilla">https://github.com/gurgeh/Guerilla</a>. It does not contain much yet.<br />  <div class="zemanta-pixie" style="height: 15px; margin-top: 10px;"></div></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>sm4096</div>
<div class='content'>
Ai building efforts start at definitions:  Ai that can<br />specify goals and weight them , acquire combine breakdown and refine strategy.<br /><br />A strategy specifies goals, their desirability and at what likelihoods to take what actions on what (set of) conditions. <br /><br />Devising strategies can be broken down into:<br />creating and assessing conditions for actions,<br />weight of goals, estimates of cost for actions,<br />estimates of effectiveness of actions, finding related strategies,<br />taking strategies apart,<br />combining strategies,<br />covering contingencies,<br />evaluating strategies</div>
</div>
<div class='comment'>
<div class='author'>Jiri Jelinek</div>
<div class='content'>
I would be interested to see the input from which this AI (when implemented) would be able to learn how to play the 5-in-a-row game.</div>
</div>
<div class='comment'>
<div class='author'>Jiri Jelinek</div>
<div class='content'>
This comment has been removed by the author.</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@acetoline No, the project is not abandoned, but thanks for asking :). I tend to post infrequent, overambitiously long posts, so a few weeks silence is normal.<br /><br />The reason the github activity is low is more silly. I am currently in something between the design and implementation stage, writing Python code with a few pseudocode elements and a lot of prose. For some reason, I have not considered this semi-code &quot;commit-worthy&quot;.<br /><br />I promise a github update this week.</div>
</div>
<div class='comment'>
<div class='author'>acetoline</div>
<div class='content'>
Hi, I noticed there hasn&#39;t been any activity on your blog or github lately. I hope you haven&#39;t abandoned the project.</div>
</div>
<div class='comment'>
<div class='author'>Jiri Jelinek</div>
<div class='content'>
Doesn&#39;t sound like a well scalable solution. Don&#39;t get overexcited/misled after some early luck in well defined toy worlds. With teaching by manual algorithm entry by techies, you aren&#39;t gonna get very far.</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
Hopefully, yes, it should be able to solve general problems using more specialized algorithms working together. It will not, however, take a set of specialized algorithms (let&#39;s say playing chess, checkers, poker and backgammon) and produce a general game playing algorithm. That is not how it achieves generality.<br /><br />It is geared towards very technical users. It takes input tasks as snippets of code and gives a  set of inputs that makes the function output true. This is called function inversion and is a fairly simple way of describing puzzles and technical problems.<br /><br />If it turns out to be a useful system for solving these types of tasks (a big IF - no one has really been able to achieve that). It would be a very good base on which to build something that can communicate with non-technical users and interact with our fuzzy world. That is not it&#39;s primary purpose, though.</div>
</div>
<div class='comment'>
<div class='author'>Jiri Jelinek</div>
<div class='content'>
Can this &#39;AGI&#39; generate general algorithms from a set of relevant non-general algorithms? Will non-technical users be able to teach this AI by describing specific (/non-general) scenarios?</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@Jiri Swedes, Norwegians, Danes and many Finns can read Swedish. That makes up a good 0.3% of the earth population :).<br /><br />Actually, I will remove that. That source code is not for human consumption yet. It is just test cases for analyzing source code, written in an odd Lisp dialect. No actual code relating to implementing either any of the algorithms I write about or the Scheduler.</div>
</div>
<div class='comment'>
<div class='author'>Mentifex</div>
<div class='content'>
One way to build a strong AI is outlined in the <a href="http://mind.sourceforge.net/aisteps.html" rel="nofollow">http://mind.sourceforge.net/aisteps.html</a> and develops into a simple but gradually <a href="http://www.scn.org/~mentifex/AiMind.html" rel="nofollow">expandable AI Mind</a>.</div>
</div>
<div class='comment'>
<div class='author'>Jiri Jelinek</div>
<div class='content'>
Don&#39;t use Swedish in the source, man! &#39;Nobody&#39; can read that ;-)</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2010/12/28/compression-prediction-and-artificial/">Compression, Prediction and Artificial Intelligence</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-12-28T00:00:00+01:00" pubdate data-updated="true">Dec 28<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Compression is one of the most powerful concepts in computing. For the normal computer user, compression is associated with making files smaller, so you can store more of them or send them faster over the Internet, but there is much more to it.<br /><br />An optimal compressor can (or could, if it existed) be used for prediction of the future of a sequence of events (weather, sports, stocks, political events, etc), for example by trying all possible continuations and examine how well it compresses given the history. Conversely, an optimal predictor that gives the correct probability of each possible next symbol can be used for optimal compression by using <a href="http://en.wikipedia.org/wiki/arithmetic_coding">arithmetic coding</a>.<br /><span class="Apple-style-span" style="font-size: large;"><br /></span><br /><span class="Apple-style-span" style="font-size: large;">Compression and prediction</span><br /><br /><i>This section on background theory contains possibly scary math and dense prose, but should be understandable for most programmers. Maybe re-read the sentences a couple of times.</i><br /><br />Ray Solomonoff has shown&nbsp;<a href="http://www.theworld.com/~rjs/chris1.pdf">[PDF]</a>&nbsp;&nbsp;that if we let Sk be the infinite set of all programs for a machine M, such that M(Sk) gives an output with X as prefix (i.e the first bits of the output is X), then the probability of X becomes the sum of the probabilities of all of its programs, where the probability of a program is&nbsp;2 ** (-|Sk|) if |Sk| is the length of the program in bits and &#8220;**&#8221; means &#8220;to the power of&#8221;. As X gets longer, the error of the predictions approach zero, if the error is calculated as the total squared probability difference.<br /><br />A technicality is that only those programs count, that does not still produce X, when the last bit of the program is removed.<br /><br />To give a slightly more concrete example, say that you have a sequence of events - a history - and encode those as a sequence of symbols, X. Let us further say that you have a machine, M, that can read a program S and output a sequence of symbols. If you have no further information on your sequence of events, then the best estimate for the probability of a symbol Z to occur next (i.e the best prediction) is given by the set of all programs that output your history X followed by Z. Programs which output X+Z and are short are weighted higher (the 2 ** (-|Sk|) part).<br /><br /><br /><div style="margin-bottom: 0px; margin-left: 0px; margin-right: 0px; margin-top: 0px;">Even more concretely, given the binary sequence 101010101, you wonder what the probability is that the next bit will be 0 given that you know nothing else of this sequence. Sum 2 ** (-program length) for all programs that output 1010101010 vs those that output 1010101011 as their first bits (they are allowed to continue outputting stuff). If we call these sums sum0 and sum1 respectively, then the probability of 0 coming next is sum0 / (sum0 + sum1) and the probability of 1 coming next is sum1 / (sum0 + sum1).</div><br /><br />Obviously you cannot find all these programs by just trying every possible program, because 1) they are infinitely many and 2) given <a href="http://en.wikipedia.org/wiki/Halting_problem">the halting problem</a> you cannot in general know if a running program is in an infinite loop or if it will eventually output X.<br /><br />There is an area of probability theory called <a href="http://en.wikipedia.org/wiki/Minimum_description_length">Minimum description length</a>, where the language is chosen to be so simple (not Turing complete) so that you can actually find the shortest program or &#8220;description&#8221;. Calculating probabilities this way is very similar to Bayesian probability, but more general.<br /><br /><span class="Apple-style-span" style="font-size: large;">Solomonoff in (almost) practice</span><br /><br />Although the point of the theorem is not to apply it directly in practice, for short sequences X we can actually try. We can avoid problem 1 above, there are infinitely many programs, by generating random programs and see if they produce X. If they do, we count them. This way we can produce an approximation of what the true sum0 and sum1 are. If we set up our random generation such that shorter programs are more likely, then we don&#8217;t have to bother with the 2 ** (-program length) part and may just have a running count for each sum. If the sequence is too long, this method will be impractical since almost no randomly generated programs will actually output X.<br /><br />Problem 2 above, when we test programs they may not halt, is harder, but Levin has proposed a way around it. If we in addition to program length use running time (number of instructions executed) as a measure of the probability of our program, we can start by generating all the programs that we intend to test and then run them all in parallel. As our execution moves forward, we will get an increasingly accurate approximation of the true sum0 and sum1, without getting stuck on infinite loops.<br /><br />If we want to get even more practical, it can be shown that the shortest program that produces X will generally dominate the others and thus it will predict the most likely next symbol. That way you can just search for programs that output X and the currently shortest program will be your best guess. Since we no longer care about the relative probability of the next symbol, but only which is most likely, the search does not have to be random. Thus we can use any method we like for finding a short program. If you search for programs that produce X and find one that almost does, you can construct a &#8220;true&#8221; solution from that one, by constructing a prefix part that hard codes the places where your original program is wrong. This will produce a longer program, where the length, and thus the &#8220;score&#8221;, is the length of the prefix + the length of your faulty solution. The size of the shortest program that outputs X is called the <a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolmogorov complexity</a> of X. The size of the shortest program that outputs X, measured in program size + log(running time), is called the <a href="http://www.scholarpedia.org/article/Algorithmic_complexity">Levin complexity</a> of X.<br /><br />One way to find these programs is to use <a href="http://en.wikipedia.org/wiki/Genetic_programming">genetic programming</a>, just take care that you don&#8217;t think that you can count the number of programs that produce X and get relative probabilities, because your search will now be skewed towards the solution (and thus its prediction) that you find first.<br /><br />A small problem is that depending on what machine you choose, i.e which instructions your programs can use and the length of these instructions, you will get different results. The method has a built in bias, since there is no one correct Turing complete language. This difference will however be smaller as X gets longer. One way to understand that is to note that any Turing complete language can emulate any other Turing complete language and that the size of such an emulator is finite. This is called the compiler theorem.<br /><br /><span class="Apple-style-span" style="font-size: large;">Compression is understanding and the Hutter Prize</span><br /><br />When we understand something, we can describe it succinctly. If I have an image of a red perfect circle, the size will be much larger if I describe the individual pixels rather than just say &#8220;a red circle of diameter d and thickness t&#8221;. When I understand what the image is depicting, I can describe it shorter. Sometimes a lossy compression of observed data will actually express the truth better than the exact data. If I take a photo of a red circle, the photo will probably not be perfect, but if I notice what the photo is showing, I can compress it as &#8220;a red circle&#8221; and some noise which I throw away, and suddenly my lossy compression is a better depiction of the truth.<br /><br />This equivalence between compression and general intelligence led Marcus Hutter to announce the <a href="http://prize.hutter1.net/">Hutter Prize</a>, where money is awarded for the best compression of 100 megabyte of English Wikipedia articles. So far the compression algorithms have been impressive (compressing the text to about 15%), but not shown much intelligence or understanding of the articles. When they do start to exhibit some understanding, I think that if they are allowed to compress the data in a slightly lossy way, the first thing that will happen is that some spelling and layout mistakes will be corrected, because these will be surprising to the compressor and thus demand an unusually long representation.<br /><br />Matt Mahoney has written a good rationale on the Hutter Prize <a href="http://cs.fit.edu/~mmahoney/compression/rationale.html">here</a>.<br /><br /><span class="Apple-style-span" style="font-size: large;">Compression in practice - the juicy stuff</span><br /><br />Compression is a powerful tool to measure success and avoid overfitting in a variety of common AI problems. The methods I laid out here are interesting mostly from a theoretical perspective, because of their prohibitively long running times.&nbsp;In my next post, I will expand on my thoughts on how you can use these results to get actual, practical algorithms for common AI problems.<br /><span class="Apple-style-span" style="font-size: large;"><br /></span></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2010/08/27/rescuing-hosed-system-using-only-bash/">Rescuing a Hosed System Using Only Bash</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-08-27T00:00:00+02:00" pubdate data-updated="true">Aug 27<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<span class="Apple-style-span" style="font-size: x-large;">Prelude</span><br />Yesterday I was in a productive mood. &#8220;Let&#8217;s upgrade the ancient Gentoo Linux install on that server that nobody dares to use because the OS is too shoddy&#8221;, I thought. Since the Gentoo image was from 2005 and never updated, it seemed impossible to upgrade it using normal methods. There were dependencies blocking each other and just an all around awful mess.&nbsp;I downloaded the latest install tarball and decided to just extract it right over the old install. &#8220;What is the worst thing that can happen&#8221;, right?<br /><br />As it turned out, nothing special happened. It all worked smoothly. Until I ran &#8220;emerge&#8221; - the package manager for Gentoo. It decided that all those installed packages were quite unnecessary and proceeded to uninstall everything. <b>Everything. </b>Until it could uninstall no more, because it had broken itself.<br /><br /><span class="Apple-style-span" style="font-size: x-large;">Challenge</span><br />Now I had a system without anything in /bin /sbin /usr/bin, etc. Everything was gone. All that I had left was two remote ssh connections from my desktop which, quite heroically, stayed up despite the best efforts of emerge. I could not open any new connections. The server itself is located on a magical island, far, far away, called Hisingen. I had no intention of making a trip there. Yet.<br /><br />Ok, what can we do with no binaries?<br />This is pretty much it:<br /><a href="http://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html">http://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html</a><br /><br />Notice that such practical commands as &#8220;ls&#8221;, &#8220;mv&#8221;, &#8220;ed&#8221; and &#8220;cp&#8221; are not built in. This means that we cannot list or copy files. Or rename them. Or move them. Or edit them. &#8220;echo&#8221; and &#8220;cd&#8221; is ok, though. Also we can create new files with echo &#8220;blabla&#8221; &gt; theFile.<br /><br />&#8220;Bwaha! All I have to do is use tab completion to see what files are in a directory&#8221;. I chuckled triumphantly to myself, my seductive beard dancing in the wind. Luckily tab completion reported that my /bin/ was full of executables. Unluckily /bin/ was not actually full of executables when I tried to run them. It seems that Bash or Linux or someone had cached the tab completion results.<br /><br />Since I had the Gentoo tbz-image still in the root directory, all I needed was a way to extract that and I would have all my precious programs back.<br /><br /><span class="Apple-style-span" style="font-size: x-large;">Remote file copy</span><br /><br />OK.. how do I get bzip2 and tar to the server? Well, using echo &#8220;&#8230;.&#8221; &gt; file, it is possible to create new files. But how would you write binary data using echo? It turns out that one can write any byte using \x-hexadecimal escape codes. Unfortunately if you write the zero-byte, \x00, echo terminates. Executables or full of zero-bytes so we need a way to write them too. Well, it turns out that echo can write zero-bytes without terminating using octal escape codes - \0000 will do the trick.<br /><br />I created a Python program for taking a binary file and convert it to several lines of the type:<br /><br /><blockquote>&gt; echo -en $&#8217;\x6e&#92;0000\x5f\x69\x6e\x69\x74&#92;0000\x6c\x69\x62\x63\x2e\x73\x6f\x2e\x36&#92;0000\x66\x66\x6c\x75\x73\x68&#92;0000\x73\x74\x72\x63\x70\x79&#92;0000\x66\x63\x68\x6d\x6f\x64&#92;0000\x65\x78\x69\x74&#92;0000\x73\x74\x72\x6e\x63\x6d\x70&#92;0000\x70\x65\x72\x72\x6f\x72&#92;0000\x73\x74\x72\x6e\x63\x70\x79&#92;0000\x73\x69\x67\x6e\x61\x6c&#92;0000\x5f\x5f\x73\x74\x61\x63\x6b\x5f\x63\x68\x6b\x5f\x66\x61\x69\x6c&#92;0000\x73\x74\x64\x69\x6e&#92;0000\x72\x65\x77&#8217; &gt; myfile</blockquote><blockquote>&gt; echo -en $&#8217;\x69\x6e\x64&#92;0000\x69\x73\x61\x74\x74\x79&#92;0000\x66\x67\x65\x74\x63&#92;0000\x73\x74\x72\x6c\x65\x6e&#92;0000\x75\x6e\x67\x65\x74\x63&#92;0000\x73\x74\x72\x73\x74\x72&#92;0000\x5f\x5f\x65\x72\x72\x6e\x6f\x5f\x6c\x6f\x63\x61\x74\x69\x6f\x6e&#92;0000\x5f\x5f\x66\x70\x72\x69\x6e\x74\x66\x5f\x63\x68\x6b&#92;0000\x66\x63\x68\x6f\x77\x6e&#92;0000\x73\x74\x64\x6f\x75\x74&#92;0000\x66\x63\x6c\x6f\x73\x65&#92;0000\x6d\x61\x6c\x6c\x6f\x63&#92;0000\x72\x65\x6d&#8217; &gt;&gt; myfile</blockquote><blockquote>&gt; echo -en $&#8217;\x6f\x76\x65&#92;0000\x5f\x5f\x6c\x78\x73\x74\x61\x74\x36\x34&#92;0000\x5f\x5f\x78\x73\x74\x61\x74\x36\x34&#92;0000\x67\x65\x74\x65\x6e\x76&#92;0000\x5f\x5f\x63\x74\x79\x70\x65\x5f\x62\x5f\x6c\x6f\x63&#92;0000\x73\x74\x64\x65\x72\x72&#92;0000\x66\x69\x6c\x65\x6e\x6f&#92;0000\x66\x77\x72\x69\x74\x65&#92;0000\x66\x72\x65\x61\x64&#92;0000\x75\x74\x69\x6d\x65&#92;0000\x66\x64\x6f\x70\x65\x6e&#92;0000\x66\x6f\x70\x65\x6e\x36\x34&#92;0000\x5f\x5f\x73\x74\x72\x63&#8217; &gt;&gt; myfile</blockquote><blockquote>&gt; echo -en $&#8217;\x61\x74\x5f\x63\x68\x6b&#92;0000\x73\x74\x72\x63\x6d\x70&#92;0000\x73\x74\x72\x65\x72\x72\x6f\x72&#92;0000\x5f\x5f\x6c\x69\x62\x63\x5f\x73\x74\x61\x72\x74\x5f\x6d\x61\x69\x6e&#92;0000\x66\x65\x72\x72\x6f\x72&#92;0000\x66\x72\x65\x65&#92;0000\x5f\x65\x64\x61\x74\x61&#92;0000\x5f\x5f\x62\x73\x73\x5f\x73\x74\x61\x72\x74&#92;0000\x5f\x65\x6e\x64&#92;0000\x47\x4c\x49\x42\x43\x5f\x32\x2e\x34&#92;0000\x47\x4c\x49\x42\x43\x5f\x32\x2e\x33&#92;0000\x47\x4c\x49&#8217; &gt;&gt; myfile</blockquote><div>Taking care to escape all the backslashes properly turned out to be a bit of a challenge.&nbsp;<i>Fun fact</i>: if you write the hex code for backslash twice, \x53\x53, Bash will first convert them to backslash and then echo will interpret them as a new escape code and convert them to one backslash.</div><div><br /></div><div>Now I could cut and paste (very) small binaries, but I needed to paste a few megabytes. &#8220;Why a few megabytes?&#8221; you wonder. Well, since emerge removed all libraries as well, I had to compile the executables with all libraries linked statically. As it turns out, this makes a small utility much larger.</div><div><br /></div><div><span class="Apple-style-span" style="font-size: x-large;">Enter Konsole and DBUS</span></div><div>Konsole is a wonderful terminal program. Not only can I write stuff in it and make the text green on black and pretend I am Neo from &#8220;the Matrix&#8221;, I can also control it programmatically via DBUS. This means that I could write a Python program that sends characters to one of my sessions. I had to divide the file up into several messages of the form I showed above, and then send them. If I sent the messages too quickly, they got garbled and everything became a mess, so after each message I had to sleep for a short time.</div><div><br /></div><div>Using this method, I reached the staggering speed of 1K (yes, a thousand bytes) per second. Not quite as snappy as my over fifteen year old 14.4K modem, that could in theory reach 14400 bits per seconds.</div><div><br /></div><div>I think that the final program turned out to be quite useful. Using it, I can send a file from one terminal to another.</div><div><br /></div><div><span class="Apple-style-span" style="font-size: x-large;">Run, Forest, run!</span></div><div>A small problem turned up. How do I execute my executables? Chmod is not accessible and umask, which is a Bash builtin, just sets the maximum allowed privileges, rather than actually deciding how new files are created. As far as I know this problem is unsolvable, if not for a tiny cheat.</div><div><br /></div><div>If you pipe text into a file that is already executable, the resulting file will be executable, even if you overwrite the old file with &#8220;&gt;&#8221;. Since we had a few executable script files lying around in /home, which emerge could not uninstall, it was a simple matter of finding an executable script file and overwriting it.</div><div><br /></div><div>If I had not had any executables, I still hoped that /proc would contain executable links to the still running programs, and that I somehow could pick an unimportant one (without knowing which is which, since I still cannot execute ls or cat or anything like that, remember?) and overwrite it. If Linux would let me.</div><div><br /></div><div><div>Using my trans-terminal copier, I managed to get the 800K&nbsp;<a href="http://www.busybox.net/">busybox</a>&nbsp;(a wonderful tool, which emulates all the standard Linux commands and then some)&nbsp;to my broken server, under the guise &#8220;feedback.py&#8221;. This turned out to pose a new problem, since busybox refuses to run under any other name than busybox or one of it&#8217;s commands. This is because busybox will check under what name it was called and emulate that command.&nbsp;Feedback.py was not one of the builtins, apparently.&nbsp;Now I needed a way to rename &nbsp;the file to busybox again, so I had to statically compile GNU coreutils (./configure LDFLAGS = &#8220;-static&#8221; is your friend) and transfer &#8220;cp&#8221;. All 700K of it.</div></div><div><br /></div><div><span class="Apple-style-span" style="font-size: x-large;">Summing up</span></div><div><br /></div><div>Even if I had not had a Gentoo install image lying around, it would not have posed a problem by now, since busybox includes both wget and ftp.</div><div><br /></div><div>I extracted my install image and without doing anything further, I could suddenly make new ssh connections again! Feeling quite heroic, I decided to blog about it, since someone else (or I in the future, God forbid) might find it useful. And here we are.</div><div><br /></div><div>Since the terminal-copy program could also conceivably be useful for someone else, I will post it somewhere public.</div><div><br /></div></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Noel D</div>
<div class='content'>
Thank you so much. I renamed a system file on AIX libcrypt.a as root and then none of the commands worked.</div>
</div>
<div class='comment'>
<div class='author'>hsteoh</div>
<div class='content'>
Thanks SO MUCH for this page!!! The past weekend, I accidentally hosed the dynamic linker on my remote server, and nothing could run (ssh can&#39;t even start a new session). The only thing left was a root bash shell over the last ssh connection I have to the box. Using your echo trick, I was able to copy a statically-linked busybox over, and recover the system.<br /><br />Just one note, though: you don&#39;t really need konsole or a python script to spool the lines over to the shell; the reason you can&#39;t just copy-n-paste 2000+ echo commands is because bash fiddles with terminal settings after every command, causing the input buffer to lose some characters after every 10 commands or so. The solution is to use downdiagonal&#39;s cat trick to copy the echo commands into a *script* on the target machine, then use (source script_filename) to run it to recreate the binary file. While bash is in the read line loop, it doesn&#39;t fiddle with the terminal, so it will actually be able to read 2000+ lines of echo commands without any mangling. (You can use a utility like xclip to copy an entire file into X11&#39;s clipboard, then transmit the whole thing with a single paste operation.)<br /><br />Of course, the cat trick adds another layer of interpolation, so you&#39;ll need to double-escape all your backslashes, etc..<br /><br />Using this method, I was able to copy about 2705 echo commands using a single copy-n-paste operation to recreate busybox.<br /><br />Thanks again, you saved my life!!</div>
</div>
<div class='comment'>
<div class='author'>previouslysilent</div>
<div class='content'>
I&#39;ve never had to recover from such a badly broken system as this, but have had to cope with a system when /lib and /usr/lib have become corrupted so that the dynamically linked /bin and /usr/bin exes have become unusable, so this was an interesting article, thanks for blogging.<br /><br />As ever, the first rule of hosing a system is DONT PANIC. It&#39;s very easy to charge in and make things worse, when some careful preservation of what still works can allow you to recover from what might seem a hopeless situation!</div>
</div>
<div class='comment'>
<div class='author'>downdiagonal</div>
<div class='content'>
I don&#39;t think there&#39;s any way to emulate chmod without some herculean effort, but I would love to see it if someone knows a way.<br /><br />Next time, instead of trying to get a copy of busybox to the machine, it would probably be better to use a copy of sash (stand-alone shell). It has much of the functionality of coreutils as shell builtins instead of using symbolic links and changing its behavior based on argv[0] as busybox does.<br /><br />Another useful trick to get files on to the machine is to use bash&#39;s net redirections to grab files from a working machine. You could pretty easily hack together a rudimentary replacement for wget by reading from and writing to /dev/tcp.<br /><br />As far as overwriting links in /proc goes, I was under the impression that /proc only contains symbolic links to executables. For example:<br /><br />$ file /proc/27252/exe <br />/proc/27252/exe: symbolic link to `/bin/bash&#39;<br /><br />When you try to overwrite a broken symbolic link it creates a new file where the link is pointing with default permissions, so I don&#39;t think that that would help.</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@downdiagonal and @h-i-r.net<br />Interesting.. My shell scripting knowledge is clearly lacking, but I think (hope..) I could have written that cat if I really needed ;).<br /><br />The problem is that even with the bash-cat, I would not have been able to make a good cp, because it would not be copying the execute permissions.<br /><br />If anybody has any suggestions on how to construct a chmod or execute a file without execute permissions, that would be very interesting and quite impressive.<br /><br />Maybe the trick I suggested with overwriting executable hard links in /proc would work?</div>
</div>
<div class='comment'>
<div class='author'>downdiagonal</div>
<div class='content'>
Emulate cat with just bash:<br /><br />(IFS=$&#39;\n&#39;;while read line;do echo &quot;$line&quot;;done) &lt; file.ext</div>
</div>
<div class='comment'>
<div class='author'>Ax0n</div>
<div class='content'>
Err&#8230; I meant echo, not cat.</div>
</div>
<div class='comment'>
<div class='author'>h-i-r.net</div>
<div class='content'>
That&#39;s some useful stuff I hadn&#39;t thought of before. I forgot cat would decode hex. Here&#39;s some stuff I whipped up that might have helped you as far as building out a few things for ls, ps and the like: http://www.h-i-r.net/2009/08/cratered-your-linux-box-here-are-some.html</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@Jeff Goldschrafe<br />&quot;cat&quot; is a program. All my programs were gone. I only had access to what Bash has built in.</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@Bjartr<br />Neat trick! I did not think of that. Before I did anything else, I found someone who had implemented ls in 1017 bytes using assembler and pasted the binary semi-manually:<br />http://www.muppetlabs.com/~breadbox/software/tiny/<br /><br />It is actually quite a capable version of ls. Later it let me see the size of the files I had transfered.</div>
</div>
<div class='comment'>
<div class='author'>Jeff Goldschrafe</div>
<div class='content'>
Couldn&#39;t you have emulated cp with &quot;cat somefile &gt; someotherfile&quot; or some such?</div>
</div>
<div class='comment'>
<div class='author'>Bjartr</div>
<div class='content'>
Instead of tab completion to find what&#39;s in a directory you can use echo *</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2010/08/19/milliblogging-essae-in-7-tweets/">Milliblogging - an Essay in 7 Tweets</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-08-19T00:00:00+02:00" pubdate data-updated="true">Aug 19<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Twitter became popular because of its 140 character restriction, orginally designed to fit an SMS.<br /><br />This restriction promises the follower that everything will be easily digested, but perhaps more important is the benefit to the writer.<br /><br />Often someone starts a blog, but then quits when every post becomes too long. Too ambitious. Twitter frees the writer of such pressure.<br /><br />Pressure to be concise is great, but I propose that the 140 char limit is too limiting to express anything interesting. Tweets are dumb.<br /><br />Instead of microblogging, I propose #milliblogging. You must constrict yourself to (maybe?) 1000 characters - the length of 7 tweets.<br /><br />Would you join such a site? Would you rather it be an extended Twitter-client or a new community?<br /><br />#Milliblogging - for people with something to say.<br /><br />(This post was also tweeted by me on <a href="http://www.twitter.com/fnedrik">http://www.twitter.com/fnedrik</a> )</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
I started out with the target of 5 tweets / 700 characters, but I found out that to express the idea itself, I needed 7 tweets.</div>
</div>
<div class='comment'>
<div class='author'>RBerenguel</div>
<div class='content'>
Interesting idea. I don&#39;t know. Usually my posts are way long&#8230; Maybe I can try to write my next post as 7 tweets to try.<br /><br />Ruben</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2010/06/16/digital-immortality-true-ai-and/">Digital Immortality, True AI and the Destruction of Mankind</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-06-16T00:00:00+02:00" pubdate data-updated="true">Jun 16<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Around the world a few people and companies are working towards the goal of <a href="http://en.wikipedia.org/wiki/Artificial_general_intelligence">strong AI</a>&nbsp;or artificial general intelligence, which is more or less the same thing. Too few, if you ask me.<br /><br />Today I was reminded of a strategy towards AGI that I have sometimes dreamed of. It is not the strategy I believe most in, but I think it is interesting nonetheless.<br /><br />What if you (assuming you are a competent programmer), from now on, tried to automate as many of your computer tasks as possible. Instead of doing something, try making the computer do it. Even if it takes you ten or a hundred times as long, your time investment will hopefully pay dividends in the future. Starting out, many things will be out of reach, but you will slowly build a knowledge base and an algorithm base that can mimic your preferences and skills. this will enable you to take on harder tasks and so on. You are building a digital assistant from the ground up.<br /><br />Maybe this undertaking is too ambitious for one person, especially if they actually wanted to get something done besides building a digital assistant. In that case, my proposal stands, but instead use a small team (Google and Microsoft, I know you have a few talented guys to spare for a grand project) that tries to automate the computer tasks of one guy.<br /><br />Take email, for example. Propose automatic actions on incoming mail, including replies, forwards and adding stuff to the calendar. Initially, very few emails will be understandable, but gradually I expect the algorithm to get better at parsing language and to get a better model of the user and the world. Perhaps one part of the knowledge base is building a <a href="http://en.wikipedia.org/wiki/Bayesian_network">Bayesian network</a>&nbsp;that models the user&#8217;s preferences. The important thing is: solve the emails one at a time, using as general rules as you can get away with, but as specialized rules as you practically have to.<br /><br />Want to look something up on Wikipedia? Make travel plans online? Make a purchasing decision? Solve it in code, as general as you can. When the AI is further advanced, you start to write documents and code collaboratively, and so forth. One way of developing the AI is to let it observe your digital life and all your actions. Ultimately, what you end up with is a digital model of yourself, that gets more and more like the original. It answers mail, reads news and maybe comments on it in tweets and blogs. In effect, you achieve digital immortality.<br /><br />Obviously, the weakness here is that I have not proposed what algorithms should be used for this digital alter ego. I do, however, feel that the task of general AI will benefit from both clever general algorithms and clever specialized algorithms and specialized knowledge. An organic hodge-podge of hacks and patches, very much like the brain itself.<br /><br />When a mathematician approaches the problem of AGI, they want a clean solution. One algorithm to bind them all, like the <a href="http://www.idsia.ch/~juergen/goedelmachine.html">G√∂del Machine</a>&nbsp;of&nbsp;<a href="http://www.idsia.ch/~juergen/">J√ºrgen Schmidhuber</a>&nbsp;and <a href="http://www.hutter1.net/">Marcus Hutter</a>. When engineers approach the same problem, they tend to engineer grand designs, like <a href="http://en.wikipedia.org/wiki/Ben_Goertzel">Ben Goertzel</a>&#8217;s <a href="http://novamente.net/">Novamente</a>&nbsp;and <a href="http://www.opencog.org/wiki/The_Open_Cognition_Project">OpenCog</a>. I can certainly see the charm of both approaches and I hope that they succeed, but maybe the most practical way forward is just to tackle one small real-world task at a time - the &#8220;guided hodge-podge&#8221; approach.<br /><br />About the destruction of mankind? No, I don&#8217;t think we will have any of that, but some smart people do. Like Michael Anissimov: <a href="http://www.acceleratingfuture.com/michael/blog/2007/04/why-is-ai-dangerous/">&#8220;Why is AI dangerous?&#8221;</a>. Still, a title is better when it involves destruction, don&#8217;t you think?</div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Michael Anissimov</div>
<div class='content'>
Why don&#39;t you think there&#39;s a risk from AI destroying us?  Just context-insensitive optimism, or what?  I suggest you check out Stephen Omohundro&#39;s paper, &quot;Basic AI Drives&quot;, and also Eliezer Yudkowsky&#39;s &quot;AI as a Positive and Negative Factor in Global Risk.</div>
</div>
<div class='comment'>
<div class='author'>Harley Mellifont</div>
<div class='content'>
The problem with most strong AI advocates like yourself is that you think that all it takes to be intelligent is to behave intelligently. This is false. In psychology, can you truly determine someones intent from their behaviour alone? Take Steven Hawking for example, he can communicate only through technology. If he didn&#39;t have that technology, he would still be highly intelligent, but not according to you since he can&#39;t behave intelligently. There is far more to intelligence than behaviour: understanding is what needs to be modelled.<br /><br />I suggest you read the book On Intelligence by Jeff Hawkins.</div>
</div>
<div class='comment'>
<div class='author'>Guili</div>
<div class='content'>
&quot;solve the emails one at a time, using as general rules as you can get away with, but as specialized rules as you practically have to&quot;.<br />From what I learned doing my PhD in NLP, the more emails you &quot;solve&quot; (i.e. parse the syntax, disambiguate the 67 possible solutions, analyze the sense of each word in its context, combine these senses, disambiguate the 670 possible interpretations), the more your general rules/ specific rules ratio will decrease. <br />I can&#39;t prove this, but it&#39;s based on my observation of several rule-based systems in NLP.</div>
</div>
<div class='comment'>
<div class='author'>Ian Ozsvald</div>
<div class='content'>
I&#39;m a part of one of those companies that&#39;s working on an AGI - the project is RIA (http://www.qtara.com/) and the beta looks just like the website. It can help you write email, use Skype, research, read the news - all via a natural language spoken interface.<br /><br />An open source equivalent by the very smart John is: http://code.google.com/p/open-allure-ds/<br /><br />I&#39;m building up a set of like-minded folk for the A.I.Cookbook, mostly using Python to solve useful problems. Some of the active projects are documented here: http://blog.aicookbook.com/ with a budding discussion group: http://groups.google.com/group/aicookbook<br /><br />Cheers,<br />Ian.</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <!-- Now we're back to normal posts. Note the links used under href in both headers.-->
        <h1 class="entry-title"><a href="/blog/2010/05/05/solving-sudoku-with-genetic-algorithms/">Solving Sudoku With Genetic Algorithms</a></h1>
      
    
    
      <p class="meta">
        








  


<time datetime="2010-05-05T00:00:00+02:00" pubdate data-updated="true">May 5<span>th</span>, 2010</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
I recently wrote a small Python library for <a href="http://en.wikipedia.org/wiki/Genetic_algorithm">genetic algorithms</a> (GA), called <a href="http://code.google.com/p/optopus">optopus</a>. One thing I tried when I played around with it was to solve a <a href="http://en.wikipedia.org/wiki/Sudoku">Sudoku</a> puzzle. There are plenty of efficient ways to solve Sudoku, but with my shiny new hammer, all problems look like nails.<br /><br />Also, I remember that I once read something from someone who tried a GA C-library on Sudoku and concluded that it was not a suitable problem. If I could solve it with my slick library, that random person on the internet, whose web page I might never find again but who may exist as far as you know, would certainly be proven wrong. A worthy cause.<br /><br /><span class="Apple-style-span" style="font-size: x-large;">Genetic algorithms</span><br />A genetic algorithm is a general way to solve optimization problems. The basic algorithm is very simple:<br /><ol><li>Create a population (vector) of random solutions (represented in a problem specific way, but often a vector of floats or ints)</li><li>Pick a few solutions and sort them according to fitness</li><li>Replace the worst solution with a new solution, which is either&nbsp;a copy of the best solution, a mutation (perturbation) of the best&nbsp;solution, an entirely new randomized solution or a cross between the two&nbsp;best solutions. These are the most common evolutionary operators, but you could dream up others that use information from existing solutions to create new potentially good solutions.</li><li>Check if you have a new global best fitness, if so, store the solution.</li><li>If too many iterations go by without improvement, the entire population&nbsp;might be stuck in a local minimum (at the bottom of a local valley, with a possible chasm&nbsp;somewhere else, so to speak). If so, kill everyone and start over at 1.</li><li>Go to 2.</li></ol>Fitness is a measure of how good a solution is, lower meaning better. This measure is performed by a fitness function that you supply. Writing a fitness function is how you describe the problem to the GA. The magnitude of the fitness values returned does not matter (in sane implementations), only how they compare to each other.<br /><br />There are other, subtly different, ways to perform the evolutionary process. Some are good and some are popular but bad. The one described above is called tournament selection and it is one of the good ways. Much can be said about the intricacies of GA but it will have to be said somewhere else, lest I digress completely.<br /><br /><span class="Apple-style-span" style="font-size: x-large;">Optopus and Sudoku</span><br />Using optopus is easy:<br /><br /><pre class="brush: python">from optopus import ga, stdgenomes<br /><br />#Now we choose a representation. We know that the answer to the puzzle must be some permutation of the digits 1 to 9, each used nine times.<br /><br />init_vect = sum([range(1,10)] * 9, []) # A vector of 81 elements<br />genome = stdgenomes.PermutateGenome (init_vect)<br /><br />#I made a few functions to calculate how many conflicts a potential Sudoku solution has. I'll show them later, but for now let us just import the package. I also found a puzzle somewhere and put it in the PUZZLE constant.<br /><br />import sudoku<br />solver = ga.GA(sudoku.ga_sudoku(sudoku.PUZZLE) , genome)<br /><br />#And now, when we have supplied the GA with a fitness function (ga_sudoku, which counts Sudoku conflicts) and a representation (genome), let us just let the solver do its magic.<br /><br />solver.evolve(target_fitness=0)<br /></pre><br />And in a few minutes (about 2.6 million iterations when I tried) the correct answer pops out!<br /><br />The nice thing about this method is that you do not have to know anything about how to solve a Sudoku puzzle or even think very hard at all. Note that I did not even bother to just let it search for the unknown values - it also has to find the digits that we already know (which should not be too hard with a decent fitness function, see below). The only bit of thinking we did was to understand that a Sudoku solution has to be a permutation of&nbsp;<i>[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9]</i>, but this merely made the evolution part faster. If we wanted to make it faster still, we could make a genome type that let us say that there are actually nine separate vectors who are each guaranteed to be a permutation of 1 to 9. We could have thought even less and represented the solution by 81 ints who are all in the range 1 to 9, by using another genome type:<br /><br /><span class="Apple-style-span" style="font-size: small;"><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;">&gt;&gt; genome = stdgenomes.EnumGenome(81, range(1,10))</span></span><br /><br />The range argument to EnumGenome does not have to be a vector of integers, it could be a vector of any objects, since they are never treated like numbers.<br /><br />In my experiment this took maybe 15 - 30 minutes to solve. For more difficult Sudoku puzzles, I would definitely go with the permutation genome, since using EnumGenome increases the search space to 9^81 or <i>196627050475552913618075908526912116283103450944214766927315415537966391196809</i> possible solutions.<br /><br />FYI, this is the puzzle in sudoku.PUZZLE:<br /><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&nbsp;&nbsp;4|8 &nbsp;| 17</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>67 |9 &nbsp;| &nbsp;&nbsp;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>5 8| 3 | &nbsp;4</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&#8212;&#8212;&#8212;&#8211;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>3 &nbsp;|74 |1 &nbsp;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&nbsp;69| &nbsp; |78&nbsp;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&nbsp;&nbsp;1| 69| &nbsp;5</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&#8212;&#8212;&#8212;&#8211;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>1 &nbsp;| 8 |3 6</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>&nbsp;&nbsp; | &nbsp;6| 91</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><b>24 | &nbsp;1|5 &nbsp;</b></span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><br /></span><br /><span class="Apple-style-span" style="font-family: inherit;">I think a Sudoku puzzle that is harder for humans would not be that much harder for optopus to solve, but I have not tested it.</span><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><br /></span><br /><span class="Apple-style-span" style="font-family: inherit;"><span class="Apple-style-span" style="font-size: x-large;">Sudoku fitness function</span></span><br /><span class="Apple-style-span" style="font-family: inherit;">OK, so that was a ridiculously easy way to solve a Sudoku puzzle, but I skipped one part that is crucial to all GA - describing the problem using a fitness function. I had to do the following:</span><br /><br /><pre class="brush: python">DIM = 9<br /><br />def one_box(solution, i):<br />    """Extract the 9 elements of a 3 x 3 box in a 9 x 9 Sudoku solution."""<br />    return solution[i:i+3] + solution[i+9:i+12] + solution[i+18:i+21]<br /><br />def boxes(solution):<br />    """Divide a flat vector into vectors with 9 elements, representing 3 x 3<br />    boxes in the corresponding 9 x 9 2D vector. These are the standard<br />    Sudoku boxes."""<br />    return [one_box(solution, i) for i in [0, 3, 6, 27, 30, 33, 54, 57, 60]]<br /><br />def splitup(solution):<br />    """Take a flat vector and make it 2D"""<br />    return [solution[i * DIM:(i + 1) * DIM] for i in xrange(DIM)]<br /><br />def consistent(solution):<br />    """Check how many different elements there are in each row.<br />    Ideally there should be DIM different elements, if there are no duplicates."""<br />    return sum(DIM - len(set(row)) for row in solution)<br /><br />def compare(xs1, xs2):<br />    """Compare two flat vectors and return how much they differ"""<br />    return sum(1 if x1 and x1 != x2 else 0 for x1, x2 in zip(xs1, xs2))<br /><br />def sudoku_fitness(flatsolution, puzzle, flatpuzzle=None):<br />    """Evaluate the fitness of flatsolution."""<br />    if not flatpuzzle:<br />        flatpuzzle = sum(puzzle, [])<br />    solution = splitup(flatsolution)<br />    fitness = consistent(solution) #check rows<br />    fitness += consistent(zip(*solution)) #check columns<br />    fitness += consistent(boxes(flatsolution)) #check boxes<br />    fitness += compare(flatpuzzle, flatsolution) * 10 #check that it matches the known digits<br />    return fitness<br /><br />def ga_sudoku(puzzle):<br />    """Return a fitness function wrapper that extracts the .genes attribute from<br />    an individual and sends it to sudoku_fitness."""<br />    flatpuzzle = sum(puzzle, []) #just a precalcing optimization<br />    def fit(guy):<br />        return sudoku_fitness(guy.genes, puzzle, flatpuzzle)<br />    return fit<br /></pre><br /><span class="Apple-style-span" style="font-family: 'Courier New', Courier, monospace;"><br /></span><br /><span class="Apple-style-span" style="font-family: inherit;">I know. This made the solution less clean. Still, I made it verbose for readability, so it is perhaps less code than it looks.</span><br /><span class="Apple-style-span" style="font-family: inherit;"><br /></span><br /><span class="Apple-style-span" style="font-family: inherit;">Take that, random internet guy!</span><br /><span class="Apple-style-span" style="font-family: inherit;"><br /></span></div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@blob Unfortunately I have no variable length genomes in optopus, but it is easy enough to create one yourself. Look at BaseGenome and perhaps take some inspiration from FloatGenome.</div>
</div>
<div class='comment'>
<div class='author'>blob</div>
<div class='content'>
Is there a built-in Genome that allows for a variable number of objects?<br /><br />Thanks! (:</div>
</div>
<div class='comment'>
<div class='author'>Stefaan</div>
<div class='content'>
I coded a Java GA for solving sudoku this year in a Meta-Heuristics course I took post grad. The best solving time I obtained from a few runs of AL Escargot was 9 minutes 41 seconds on a 2.66ghz core2 workstation, other problems took from sub one to 40 odd seconds depending on the difficulty. In the end the GA used four different methods of applying selection pressure, 4 more methods to then pare up parents, six different crossover methods, a modified island model and population restarting conditions&#8230; Needless to say comparitively to other meta-heuristics it is a very inefficient method.</div>
</div>
<div class='comment'>
<div class='author'>Cleve</div>
<div class='content'>
Human puzzle solvers and computers use very different approaches for Sudoku.  Humans are good at finding patterns.  Computers use brute force with genetic algorithms or other forms of recursive backtracking.  Take a look at:<br />   http://www.mathworks.com/moler/exm/chapters/sudoku.pdf</div>
</div>
<div class='comment'>
<div class='author'>Jerren</div>
<div class='content'>
So there is a GA to solve Sudoku.  That means there must be a constructive algorithm to solve it too.<br />What is the constructive algorithm?</div>
</div>
<div class='comment'>
<div class='author'>StartBreakingFree.com</div>
<div class='content'>
Pretty cool, so did it solve one sudoku puzzle or did it evolve an algorithm to solve sudoku puzzles in general?<br /><br />Thanks for posting it!</div>
</div>
<div class='comment'>
<div class='author'>micks</div>
<div class='content'>
Very interesting way to solve sudoku.<br /><br />I am just curious, exactly how long did it take for you to solve Sudoku? <br />I have a solution that solves Sudoku (among other tougher problems) very fast. <br />I just want to know your number before telling(bragging, as some might say) about mine.<br /><br />I just wanna compare the speed of the two solutions, yours and mine.<br />Really good post.</div>
</div>
<div class='comment'>
<div class='author'>vaevictus-net</div>
<div class='content'>
Seems like genetic algorithms for sudoku solutions are a decent example of GA.  But I think it might be fun/interesting to use GA to build some sort of logic engine to solve sudokus.  :)</div>
</div>
<div class='comment'>
<div class='author'>Daivd</div>
<div class='content'>
@albert<br /><br />I agree, that is a good approach.</div>
</div>
<div class='comment'>
<div class='author'>albert</div>
<div class='content'>
This is better:<br />http://norvig.com/sudoku.html</div>
</div>
<div class='comment'>
<div class='author'>Doug</div>
<div class='content'>
Damn, This is mind numbing good&#8230;</div>
</div>
</div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/11/22/compile-time-loops-in-c-plus-plus-11-with-trampolines-and-exponential-recursion/">Compile time loops in C++11 with trampolines and exponential recursion</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/10/31/c-plus-plus-11-and-boost-succinct-like-python/">C++11 and Boost - succinct like Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/28/no/">No, really. Use Zsh.</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/09/27/octopress-and-github-as-blogging-platform/">Octopress and Github as a blogging platform</a>
      </li>
    
      <li class="post">
        <a href="/blog/2011/11/10/guerilla-my-attempt-to-build-strong-ai/">Guerilla - my attempt to build a strong AI</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/gurgeh">@gurgeh</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'gurgeh',
            count: 5,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("fnedrik", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/fnedrik" class="twitter-follow-button" data-show-count="false">Follow @fnedrik</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - David Fendrich -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'ifho';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>




<a title="Real Time Analytics" href="http://getclicky.com/100529738"><img alt="Real Time Analytics" src="//static.getclicky.com/media/links/badge.gif" border="0" /></a>
<script src="//static.getclicky.com/js" type="text/javascript"></script>
<script type="text/javascript">try{ clicky.init(100529738); }catch(e){}</script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/100529738ns.gif" /></p></noscript>


</body>
</html>
